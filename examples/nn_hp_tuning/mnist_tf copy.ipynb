{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-17 14:39:24.054654: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-17 14:39:24.062734: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1742236764.073881 1679097 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1742236764.077397 1679097 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-17 14:39:24.087837: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/rizki/llmize/llmize/methods/opro.py:64: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  \"\"\"\n",
      "/home/rizki/llmize/llmize/methods/hlmsa.py:103: SyntaxWarning: invalid escape sequence '\\h'\n",
      "  \"\"\"\n",
      "\u001b[0m/home/rizki/llmize/llmize/methods/hlmsa.py:196: SyntaxWarning: invalid escape sequence '\\h'\n",
      "  hp_text = f\"\"\"The hyperparameter (cooling rate) used in previous step is: <hp> {hp} <\\hp>\"\"\"\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from llmize import OPRO\n",
    "import llmize\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(units, dropout, learning_rate):\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        keras.layers.Dense(units, activation='relu'),\n",
    "        keras.layers.Dropout(dropout),\n",
    "        keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def objective_function(hps, x_train, y_train, x_test, y_test, epochs=5):\n",
    "    units, dropout, learning_rate = hps\n",
    "    model = build_model(units, dropout, learning_rate)\n",
    "    model.fit(x_train, y_train, epochs=epochs, validation_data=(x_test, y_test), verbose=0)\n",
    "    _, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "    return accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rizki/anaconda3/envs/genai_env/lib/python3.12/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "\u001b[0mI0000 00:00:1742236765.982626 1679097 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4480 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:02:00.0, compute capability: 7.5\n",
      "I0000 00:00:1742236767.531213 1679394 service.cc:148] XLA service 0x7f03b80043f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1742236767.531245 1679394 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti, Compute Capability 7.5\n",
      "2025-03-17 14:39:27.544907: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1742236767.590352 1679394 cuda_dnn.cc:529] Loaded cuDNN version 90800\n",
      "I0000 00:00:1742236768.205893 1679394 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "\n",
    "accuracy = objective_function(hps=[16, 0.2, 0.001], x_train=x_train, y_train=y_train, x_test=x_test, y_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9408000111579895\u001b[0m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "# Generate batch_size of random hps\n",
    "random_hps = []\n",
    "for _ in range(batch_size):\n",
    "    units = np.random.randint(2, 128)  # Random number of units between 16-512\n",
    "    dropout = round(np.random.uniform(0.1, 0.3), 2)  # Random dropout rate between 0.1-0.5 \n",
    "    learning_rate = round(np.random.uniform(0.0001, 0.01), 4)  # Random learning rate between 0.0001-0.01\n",
    "    random_hps.append([units, dropout, learning_rate])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[104, 0.26, 0.0019], [73, 0.22, 0.0016], [84, 0.12, 0.0046], [118, 0.22, 0.0071], [23, 0.11, 0.0072], [31, 0.14, 0.0019], [22, 0.22, 0.0062], [126, 0.19, 0.003], [60, 0.18, 0.0006], [61, 0.17, 0.0046], [48, 0.22, 0.0039], [117, 0.22, 0.0006], [52, 0.24, 0.0046], [19, 0.29, 0.0097], [115, 0.18, 0.0003], [3, 0.24, 0.0045]]\u001b[0m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "print(random_hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9768999814987183\u001b[0m\n",
      "\u001b[0m0.9745000004768372\u001b[0m\n",
      "\u001b[0m0.9672999978065491\u001b[0m\n",
      "\u001b[0m0.9641000032424927\u001b[0m\n",
      "\u001b[0m0.9473999738693237\u001b[0m\n",
      "\u001b[0m0.9603000283241272\u001b[0m\n",
      "\u001b[0m0.9369999766349792\u001b[0m\n",
      "\u001b[0m0.9763000011444092\u001b[0m\n",
      "\u001b[0m0.9700000286102295\u001b[0m\n",
      "\u001b[0m0.9606999754905701\u001b[0m\n",
      "\u001b[0m0.9678000211715698\u001b[0m\n",
      "\u001b[0m0.9760000109672546\u001b[0m\n",
      "\u001b[0m0.9635999798774719\u001b[0m\n",
      "\u001b[0m0.9085999727249146\u001b[0m\n",
      "\u001b[0m0.9692999720573425\u001b[0m\n",
      "\u001b[0m0.503000020980835\u001b[0m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Evaluate accuracy for each hps\n",
    "accuracies = []\n",
    "for hps in random_hps:\n",
    "    accuracy = objective_function(hps=hps, x_train=x_train, y_train=y_train, \n",
    "                                x_test=x_test, y_test=y_test)\n",
    "    print(accuracy)\n",
    "    accuracies.append(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================================================================================================\u001b[0m\n",
      "\u001b[0mPrompt:\u001b[0m\n",
      "\u001b[0mTask: Optimize the hyperparameters for a feedforward neural network model to classify handwritten digits in the MNIST dataset.\n",
      "\n",
      "Model Architecture:\n",
      "\n",
      "Input Layer: 28x28 pixel images (flattened to 784 inputs)\n",
      "Hidden Layer: A single dense layer with configurable number of units, activated by ReLU\n",
      "Dropout Layer: Added for regularization to prevent overfitting\n",
      "Output Layer: Dense layer with 10 units (representing digits 0-9), softmax activation for multi-class classification\n",
      "Hyperparameters to Optimize:\n",
      "\n",
      "units: The number of neurons in the hidden layer\n",
      "dropout: The dropout rate (probability of randomly deactivating neurons during training)\n",
      "learning_rate: The learning rate for the Adam optimizer\n",
      "Training Setup:\n",
      "\n",
      "Optimizer: Adam\n",
      "Loss Function: Sparse categorical cross-entropy (ideal for multi-class classification tasks)\n",
      "Metrics: Accuracy\n",
      "Epochs: 5 epochs\n",
      "Validation data used during training\n",
      "Data Processing:\n",
      "\n",
      "Dataset: MNIST\n",
      "Pixel values normalized to range [0, 1] by dividing by 255.0\n",
      "Request: Suggest optimized values for the following hyperparameters based on your understanding of the dataset and model:\n",
      "\n",
      "Number of neurons in the hidden layer (units)\n",
      "Dropout rate (dropout)\n",
      "Learning rate (learning_rate)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Below are some examples of solutions and their scores:\n",
      "\n",
      "<sol> 104,0.26,0.0019 <\\sol>\n",
      "score: 0.977\n",
      "\n",
      "<sol> 73,0.22,0.0016 <\\sol>\n",
      "score: 0.975\n",
      "\n",
      "<sol> 84,0.12,0.0046 <\\sol>\n",
      "score: 0.967\n",
      "\n",
      "<sol> 118,0.22,0.0071 <\\sol>\n",
      "score: 0.964\n",
      "\n",
      "<sol> 23,0.11,0.0072 <\\sol>\n",
      "score: 0.947\n",
      "\n",
      "<sol> 31,0.14,0.0019 <\\sol>\n",
      "score: 0.960\n",
      "\n",
      "<sol> 22,0.22,0.0062 <\\sol>\n",
      "score: 0.937\n",
      "\n",
      "<sol> 126,0.19,0.003 <\\sol>\n",
      "score: 0.976\n",
      "\n",
      "<sol> 60,0.18,0.0006 <\\sol>\n",
      "score: 0.970\n",
      "\n",
      "<sol> 61,0.17,0.0046 <\\sol>\n",
      "score: 0.961\n",
      "\n",
      "<sol> 48,0.22,0.0039 <\\sol>\n",
      "score: 0.968\n",
      "\n",
      "<sol> 117,0.22,0.0006 <\\sol>\n",
      "score: 0.976\n",
      "\n",
      "<sol> 52,0.24,0.0046 <\\sol>\n",
      "score: 0.964\n",
      "\n",
      "<sol> 19,0.29,0.0097 <\\sol>\n",
      "score: 0.909\n",
      "\n",
      "<sol> 115,0.18,0.0003 <\\sol>\n",
      "score: 0.969\n",
      "\n",
      "<sol> 3,0.24,0.0045 <\\sol>\n",
      "score: 0.503\n",
      "\n",
      "\n",
      "Generate exactly 5 new solutions that:\n",
      "- Are distinct from all previous solutions.\n",
      "- Have higher scores than the highest provided.\n",
      "- Respect the relationships based on logical reasoning.\n",
      "\n",
      "Each solution should start with <sol> and end with <\\sol> with a comma between parameters.\n",
      "Make sure the length of solutions match examples given. Don't guess for the scores as they will be calculated by an objective function.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0mResponse:\u001b[0m\n",
      "\u001b[0mBased on the trends observed in the provided solutions and the characteristics of the MNIST dataset and feedforward neural networks, here are five new\n",
      "hyperparameter combinations designed to potentially achieve higher accuracy:\n",
      "\n",
      "*   **Number of Neurons (units):** The higher performing models tend to have a neuron count above 60, and up to around 120. We should keep that range.\n",
      "*   **Dropout Rate (dropout):** A dropout rate between 0.1 and 0.3 seems effective.\n",
      "*   **Learning Rate (learning_rate):** The learning rate seems to perform best in the range of 0.0001 and 0.002. Lower values could provide better\n",
      "convergence, especially combined with dropout.\n",
      "\n",
      "Here are five new, distinct, and potentially improved hyperparameter combinations:\n",
      "\n",
      "<sol> 95,0.15,0.0012 <\\sol>\n",
      "<sol> 108,0.24,0.0008 <\\sol>\n",
      "<sol> 79,0.19,0.0015 <\\sol>\n",
      "<sol> 121,0.16,0.0021 <\\sol>\n",
      "<sol> 87,0.27,0.0009 <\\sol>\u001b[0m\n",
      "\u001b[0m======================================================================================================================================================\u001b[0m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "with open(\"mnist_tf.txt\", \"r\") as f:\n",
    "    problem_text = f.read()\n",
    "\n",
    "obj_func = lambda x: objective_function(x, x_train, y_train, x_test, y_test)\n",
    "\n",
    "\n",
    "# Initialize the OPRO optimizer\n",
    "opro = OPRO(problem_text=problem_text, obj_func=obj_func,\n",
    "            llm_model=\"gemma-3-27b-it\", api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "\n",
    "prompt = opro.get_sample_prompt(init_samples=random_hps, init_scores=accuracies, optimization_type=\"maximize\")\n",
    "response = opro.get_sample_response(prompt)\n",
    "\n",
    "llmize.utils.pretty_print(prompt=prompt, response=response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from llmize.callbacks import EarlyStopping, AdaptTempOnPlateau, OptimalScoreStopping\n",
    "\n",
    "# Define the early stopping callback\n",
    "earlystop_callback = EarlyStopping(monitor='best_score', min_delta=0.001, patience=50, verbose=1)\n",
    "\n",
    "# Define the optimal score stopping callback\n",
    "optimal_score_callback = OptimalScoreStopping(optimal_score=0.990, tolerance=0.005)\n",
    "\n",
    "# Define the temperature adaptation callback\n",
    "adapt_temp_callback = AdaptTempOnPlateau(monitor='best_score', init_temperature=1.0, min_delta=0.001, patience=20, factor=1.1, max_temperature=1.9, verbose=1)\n",
    "\n",
    "callbacks = [earlystop_callback, optimal_score_callback, adapt_temp_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37mRunning OPRO optimization with 250 steps and batch size 16...\u001b[0m\n",
      "\u001b[0m\u001b[37mStep 0 - Best Initial Score: 0.977, Average Initial Score: 0.933\u001b[0m\n",
      "\u001b[0m\u001b[37mStep 1 - Current Best Score: 0.977, Average Batch Score: 0.973 - Best Batch Score: 0.976\u001b[0m\n",
      "\u001b[0m\u001b[37mNo improvement in best_score. Patience count: 1/50\u001b[0m\n",
      "\u001b[0m\u001b[37mStep 2 - Current Best Score: 0.978, Average Batch Score: 0.976 - Best Batch Score: 0.978\u001b[0m\n",
      "\u001b[0m\u001b[37mStep 3 - Current Best Score: 0.980, Average Batch Score: 0.977 - Best Batch Score: 0.980\u001b[0m\n",
      "\u001b[0m\u001b[37mStep 4 - Current Best Score: 0.980, Average Batch Score: 0.977 - Best Batch Score: 0.980\u001b[0m\n",
      "\u001b[0m\u001b[37mNo improvement in best_score. Patience count: 1/50\u001b[0m\n",
      "\u001b[0m\u001b[37mStep 5 - Current Best Score: 0.980, Average Batch Score: 0.978 - Best Batch Score: 0.980\u001b[0m\n",
      "\u001b[0m\u001b[37mNo improvement in best_score. Patience count: 2/50\u001b[0m\n",
      "\u001b[0m\u001b[37mStep 6 - Current Best Score: 0.980, Average Batch Score: 0.977 - Best Batch Score: 0.980\u001b[0m\n",
      "\u001b[0m\u001b[37mNo improvement in best_score. Patience count: 3/50\u001b[0m\n",
      "\u001b[0m\u001b[37mStep 7 - Current Best Score: 0.980, Average Batch Score: 0.977 - Best Batch Score: 0.980\u001b[0m\n",
      "\u001b[0m\u001b[37mNo improvement in best_score. Patience count: 4/50\u001b[0m\n",
      "\u001b[0m\u001b[37mStep 8 - Current Best Score: 0.980, Average Batch Score: 0.976 - Best Batch Score: 0.979\u001b[0m\n",
      "\u001b[0m\u001b[37mNo improvement in best_score. Patience count: 5/50\u001b[0m\n",
      "\u001b[0m\u001b[37mStep 9 - Current Best Score: 0.980, Average Batch Score: 0.977 - Best Batch Score: 0.979\u001b[0m\n",
      "\u001b[0m\u001b[37mNo improvement in best_score. Patience count: 6/50\u001b[0m\n",
      "\u001b[0m\u001b[37mStep 10 - Current Best Score: 0.980, Average Batch Score: 0.978 - Best Batch Score: 0.979\u001b[0m\n",
      "\u001b[0m\u001b[37mNo improvement in best_score. Patience count: 7/50\u001b[0m\n",
      "\u001b[0m\u001b[37mStep 11 - Current Best Score: 0.980, Average Batch Score: 0.978 - Best Batch Score: 0.980\u001b[0m\n",
      "\u001b[0m\u001b[37mNo improvement in best_score. Patience count: 8/50\u001b[0m\n",
      "\u001b[0m\u001b[37mStep 12 - Current Best Score: 0.981, Average Batch Score: 0.978 - Best Batch Score: 0.981\u001b[0m\n",
      "\u001b[0m\u001b[37mNo improvement in best_score. Patience count: 9/50\u001b[0m\n",
      "\u001b[0m\u001b[37mStep 13 - Current Best Score: 0.981, Average Batch Score: 0.978 - Best Batch Score: 0.979\u001b[0m\n",
      "\u001b[0m\u001b[37mNo improvement in best_score. Patience count: 10/50\u001b[0m\n",
      "\u001b[0m\u001b[37mStep 14 - Current Best Score: 0.981, Average Batch Score: 0.978 - Best Batch Score: 0.979\u001b[0m\n",
      "\u001b[0m\u001b[37mNo improvement in best_score. Patience count: 11/50\u001b[0m\n",
      "\u001b[0m\u001b[37mStep 15 - Current Best Score: 0.981, Average Batch Score: 0.977 - Best Batch Score: 0.979\u001b[0m\n",
      "\u001b[0m\u001b[37mNo improvement in best_score. Patience count: 12/50\u001b[0m\n",
      "\u001b[0m\u001b[37mStep 16 - Current Best Score: 0.981, Average Batch Score: 0.978 - Best Batch Score: 0.980\u001b[0m\n",
      "\u001b[0m\u001b[37mNo improvement in best_score. Patience count: 13/50\u001b[0m\n",
      "\u001b[0m\u001b[37mStep 17 - Current Best Score: 0.981, Average Batch Score: 0.977 - Best Batch Score: 0.979\u001b[0m\n",
      "\u001b[0m\u001b[37mNo improvement in best_score. Patience count: 14/50\u001b[0m\n",
      "\u001b[0m\u001b[37mStep 18 - Current Best Score: 0.981, Average Batch Score: 0.978 - Best Batch Score: 0.980\u001b[0m\n",
      "\u001b[0m\u001b[37mNo improvement in best_score. Patience count: 15/50\u001b[0m\n",
      "\u001b[0m\u001b[37mStep 19 - Current Best Score: 0.981, Average Batch Score: 0.977 - Best Batch Score: 0.979\u001b[0m\n",
      "\u001b[0m\u001b[37mNo improvement in best_score. Patience count: 16/50\u001b[0m\n",
      "\u001b[0m\u001b[37mStep 20 - Current Best Score: 0.981, Average Batch Score: 0.978 - Best Batch Score: 0.979\u001b[0m\n",
      "\u001b[0m\u001b[37mNo improvement in best_score. Patience count: 17/50\u001b[0m\n",
      "\u001b[0m\u001b[37mStep 21 - Current Best Score: 0.981, Average Batch Score: 0.978 - Best Batch Score: 0.981\u001b[0m\n",
      "\u001b[0m\u001b[37mNo improvement in best_score. Patience count: 18/50\u001b[0m\n",
      "\u001b[0m\u001b[37mStep 22 - Current Best Score: 0.981, Average Batch Score: 0.978 - Best Batch Score: 0.979\u001b[0m\n",
      "\u001b[0m\u001b[37mNo improvement in best_score. Patience count: 19/50\u001b[0m\n",
      "\u001b[0m\u001b[37mStep 23 - Current Best Score: 0.981, Average Batch Score: 0.978 - Best Batch Score: 0.979\u001b[0m\n",
      "\u001b[0m\u001b[37mNo improvement in best_score. Patience count: 20/50\u001b[0m\n",
      "\u001b[0m\u001b[37mNo improvement in best_score for 20 steps. Adapted temperature to 1.10.\u001b[0m\n",
      "\u001b[0m\u001b[37mStep 24 - Current Best Score: 0.981, Average Batch Score: 0.978 - Best Batch Score: 0.980\u001b[0m\n",
      "\u001b[0m\u001b[37mNo improvement in best_score. Patience count: 21/50\u001b[0m\n",
      "\u001b[0m\u001b[37mStep 25 - Current Best Score: 0.981, Average Batch Score: 0.978 - Best Batch Score: 0.980\u001b[0m\n",
      "\u001b[0m\u001b[37mNo improvement in best_score. Patience count: 22/50\u001b[0m\n",
      "\u001b[0m\u001b[37mStep 26 - Current Best Score: 0.981, Average Batch Score: 0.978 - Best Batch Score: 0.980\u001b[0m\n",
      "\u001b[0m\u001b[37mNo improvement in best_score. Patience count: 23/50\u001b[0m\n",
      "\u001b[0m\u001b[37mStep 27 - Current Best Score: 0.981, Average Batch Score: 0.978 - Best Batch Score: 0.980\u001b[0m\n",
      "\u001b[0m\u001b[37mNo improvement in best_score. Patience count: 24/50\u001b[0m\n",
      "\u001b[0m\u001b[37mStep 28 - Current Best Score: 0.981, Average Batch Score: 0.978 - Best Batch Score: 0.980\u001b[0m\n",
      "\u001b[0m\u001b[37mNo improvement in best_score. Patience count: 25/50\u001b[0m\n",
      "\u001b[0m\u001b[37mStep 29 - Current Best Score: 0.981, Average Batch Score: 0.978 - Best Batch Score: 0.979\u001b[0m\n",
      "\u001b[0m\u001b[37mNo improvement in best_score. Patience count: 26/50\u001b[0m\n",
      "\u001b[0m\u001b[37mStep 30 - Current Best Score: 0.981, Average Batch Score: 0.978 - Best Batch Score: 0.981\u001b[0m\n",
      "\u001b[0m\u001b[37mNo improvement in best_score. Patience count: 27/50\u001b[0m\n",
      "\u001b[0m\u001b[37mStep 31 - Current Best Score: 0.981, Average Batch Score: 0.978 - Best Batch Score: 0.981\u001b[0m\n",
      "\u001b[0m\u001b[37mNo improvement in best_score. Patience count: 28/50\u001b[0m\n",
      "\u001b[0m\u001b[37mStep 32 - Current Best Score: 0.981, Average Batch Score: 0.978 - Best Batch Score: 0.980\u001b[0m\n",
      "\u001b[0m\u001b[37mNo improvement in best_score. Patience count: 29/50\u001b[0m\n",
      "\u001b[0m\u001b[37mStep 33 - Current Best Score: 0.981, Average Batch Score: 0.978 - Best Batch Score: 0.981\u001b[0m\n",
      "\u001b[0m\u001b[37mNo improvement in best_score. Patience count: 30/50\u001b[0m\n",
      "\u001b[0m\u001b[37mStep 34 - Current Best Score: 0.981, Average Batch Score: 0.978 - Best Batch Score: 0.980\u001b[0m\n",
      "\u001b[0m\u001b[37mNo improvement in best_score. Patience count: 31/50\u001b[0m\n",
      "\u001b[0m\u001b[37mStep 35 - Current Best Score: 0.981, Average Batch Score: 0.978 - Best Batch Score: 0.980\u001b[0m\n",
      "\u001b[0m\u001b[37mNo improvement in best_score. Patience count: 32/50\u001b[0m\n",
      "\u001b[0m\u001b[37mStep 36 - Current Best Score: 0.981, Average Batch Score: 0.977 - Best Batch Score: 0.980\u001b[0m\n",
      "\u001b[0m\u001b[37mNo improvement in best_score. Patience count: 33/50\u001b[0m\n",
      "\u001b[0m\u001b[37mStep 37 - Current Best Score: 0.981, Average Batch Score: 0.978 - Best Batch Score: 0.981\u001b[0m\n",
      "\u001b[0m\u001b[37mStep 38 - Current Best Score: 0.981, Average Batch Score: 0.978 - Best Batch Score: 0.980\u001b[0m\n",
      "\u001b[0m\u001b[37mNo improvement in best_score. Patience count: 1/50\u001b[0m\n",
      "\u001b[0m\u001b[37mStep 39 - Current Best Score: 0.981, Average Batch Score: 0.978 - Best Batch Score: 0.979\u001b[0m\n",
      "\u001b[0m\u001b[37mNo improvement in best_score. Patience count: 2/50\u001b[0m\n",
      "\u001b[0m\u001b[37mStep 40 - Current Best Score: 0.981, Average Batch Score: 0.979 - Best Batch Score: 0.981\u001b[0m\n",
      "\u001b[0m\u001b[37mNo improvement in best_score. Patience count: 3/50\u001b[0m\n",
      "\u001b[0m\u001b[37mStep 41 - Current Best Score: 0.981, Average Batch Score: 0.978 - Best Batch Score: 0.979\u001b[0m\n",
      "\u001b[0m\u001b[37mNo improvement in best_score. Patience count: 4/50\u001b[0m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "results = opro.maximize(init_samples=random_hps, init_scores=accuracies, num_steps=250, batch_size=batch_size, callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llmize.utils.plotting import plot_scores\n",
    "\n",
    "plot_scores(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
