{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from llmize import OPRO\n",
    "import llmize\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(units, dropout, learning_rate):\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        keras.layers.Dense(units, activation='relu'),\n",
    "        keras.layers.Dropout(dropout),\n",
    "        keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def objective_function(hps, x_train, y_train, x_test, y_test, epochs=3):\n",
    "    units, dropout, learning_rate = hps\n",
    "    model = build_model(units, dropout, learning_rate)\n",
    "    model.fit(x_train, y_train, epochs=epochs, validation_data=(x_test, y_test), verbose=0)\n",
    "    _, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "    return accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "\n",
    "accuracy = objective_function(hps=[16, 0.2, 0.001], x_train=x_train, y_train=y_train, x_test=x_test, y_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9284999966621399\u001b[0m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "# Generate batch_size of random hps\n",
    "random_hps = []\n",
    "for _ in range(batch_size):\n",
    "    units = np.random.randint(2, 16)  \n",
    "    dropout = round(np.random.uniform(0.3, 0.5), 2)  \n",
    "    learning_rate = round(np.random.uniform(0.0001, 0.01), 4) \n",
    "    random_hps.append([units, dropout, learning_rate])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8, 0.46, 0.0019], [9, 0.42, 0.0016], [4, 0.32, 0.0046], [6, 0.42, 0.0071], [7, 0.31, 0.0072], [15, 0.34, 0.0019], [6, 0.42, 0.0062], [14, 0.39, 0.003]]\u001b[0m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "print(random_hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8781999945640564\u001b[0m\n",
      "\u001b[0m0.8810999989509583\u001b[0m\n",
      "\u001b[0m0.6845999956130981\u001b[0m\n",
      "\u001b[0m0.7671999931335449\u001b[0m\n",
      "\u001b[0m0.8616999983787537\u001b[0m\n",
      "\u001b[0m0.9182999730110168\u001b[0m\n",
      "\u001b[0m0.748199999332428\u001b[0m\n",
      "\u001b[0m0.9085000157356262\u001b[0m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Evaluate accuracy for each hps\n",
    "accuracies = []\n",
    "for hps in random_hps:\n",
    "    accuracy = objective_function(hps=hps, x_train=x_train, y_train=y_train, \n",
    "                                x_test=x_test, y_test=y_test)\n",
    "    print(accuracy)\n",
    "    accuracies.append(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================================================================================================\u001b[0m\n",
      "\u001b[0mPrompt:\u001b[0m\n",
      "\u001b[0mTask: Optimize the hyperparameters for a feedforward neural network model to classify handwritten digits in the MNIST dataset.\n",
      "\n",
      "Model Architecture:\n",
      "\n",
      "Input Layer: 28x28 pixel images (flattened to 784 inputs)\n",
      "Hidden Layer: A single dense layer with configurable number of units, activated by ReLU\n",
      "Dropout Layer: Added for regularization to prevent overfitting\n",
      "Output Layer: Dense layer with 10 units (representing digits 0-9), softmax activation for multi-class classification\n",
      "\n",
      "Hyperparameters to Optimize:\n",
      "\n",
      "units: The number of neurons in the hidden layer\n",
      "dropout: The dropout rate (probability of randomly deactivating neurons during training)\n",
      "learning_rate: The learning rate for the Adam optimizer\n",
      "\n",
      "Training Setup:\n",
      "\n",
      "Optimizer: Adam\n",
      "Loss Function: Sparse categorical cross-entropy (ideal for multi-class classification tasks)\n",
      "Metrics: Accuracy\n",
      "Epochs: 5 epochs\n",
      "Validation data used during training\n",
      "\n",
      "Data Processing:\n",
      "\n",
      "Dataset: MNIST\n",
      "Pixel values normalized to range [0, 1] by dividing by 255.0\n",
      "Request: Suggest optimized values for the following hyperparameters based on your understanding of the dataset and model:\n",
      "\n",
      "Number of neurons in the hidden layer (units)\n",
      "Dropout rate (dropout)\n",
      "Learning rate (learning_rate)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Below are some examples of solutions and their scores:\n",
      "\n",
      "<sol> 8,0.46,0.0019 </sol>\n",
      "score: 0.878\n",
      "\n",
      "<sol> 9,0.42,0.0016 </sol>\n",
      "score: 0.881\n",
      "\n",
      "<sol> 4,0.32,0.0046 </sol>\n",
      "score: 0.685\n",
      "\n",
      "<sol> 6,0.42,0.0071 </sol>\n",
      "score: 0.767\n",
      "\n",
      "<sol> 7,0.31,0.0072 </sol>\n",
      "score: 0.862\n",
      "\n",
      "<sol> 15,0.34,0.0019 </sol>\n",
      "score: 0.918\n",
      "\n",
      "<sol> 6,0.42,0.0062 </sol>\n",
      "score: 0.748\n",
      "\n",
      "<sol> 14,0.39,0.003 </sol>\n",
      "score: 0.909\n",
      "\n",
      "\n",
      "Generate exactly 5 new solutions that:\n",
      "- Are distinct from all previous solutions.\n",
      "- Have higher scores than the highest provided.\n",
      "- Respect the relationships based on logical reasoning.\n",
      "\n",
      "Each solution should start with <sol> and end with </sol> with a comma between parameters.\n",
      "Make sure the length of solutions match examples given. Don't guess for the scores as they will be calculated by an objective function.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0mResponse:\u001b[0m\n",
      "\u001b[0mHere are 5 new solutions, aiming for higher scores than 0.918, while considering the relationships observed in the provided examples:\n",
      "\n",
      "<sol> 12,0.36,0.0015 </sol>\n",
      "<sol> 16,0.38,0.0012 </sol>\n",
      "<sol> 10,0.40,0.0020 </sol>\n",
      "<sol> 18,0.35,0.0010 </sol>\n",
      "<sol> 13,0.37,0.0017 </sol>\u001b[0m\n",
      "\u001b[0m======================================================================================================================================================\u001b[0m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "with open(\"mnist_tf.txt\", \"r\") as f:\n",
    "    problem_text = f.read()\n",
    "\n",
    "obj_func = lambda x: objective_function(x, x_train, y_train, x_test, y_test)\n",
    "\n",
    "\n",
    "# Initialize the OPRO optimizer\n",
    "opro = OPRO(problem_text=problem_text, obj_func=obj_func,\n",
    "            llm_model=\"gemma-3-27b-it\", api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "\n",
    "prompt = opro.get_sample_prompt(init_samples=random_hps, init_scores=accuracies, optimization_type=\"maximize\")\n",
    "response = opro.get_sample_response(prompt)\n",
    "\n",
    "llmize.utils.pretty_print(prompt=prompt, response=response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llmize.callbacks import EarlyStopping, AdaptTempOnPlateau, OptimalScoreStopping\n",
    "\n",
    "# Define the early stopping callback\n",
    "earlystop_callback = EarlyStopping(monitor='best_score', min_delta=0.001, patience=5, verbose=1)\n",
    "\n",
    "# Define the optimal score stopping callback\n",
    "optimal_score_callback = OptimalScoreStopping(optimal_score=0.990, tolerance=0.005)\n",
    "\n",
    "# Define the temperature adaptation callback\n",
    "adapt_temp_callback = AdaptTempOnPlateau(monitor='best_score', init_temperature=1.0, min_delta=0.001, patience=2, factor=1.1, max_temperature=1.9, verbose=1)\n",
    "\n",
    "callbacks = [earlystop_callback, optimal_score_callback, adapt_temp_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37mRunning OPRO optimization with 250 steps and batch size 8...\u001b[0m\n",
      "\u001b[0m\u001b[37mStep 0 - Best Initial Score: 0.918, Average Initial Score: 0.831\u001b[0m\n",
      "\u001b[0m\u001b[37mStep 1 - Current Best Score: 0.931, Average Batch Score: 0.908 - Best Batch Score: 0.931\u001b[0m\n",
      "\u001b[0m\u001b[37mNo improvement in best_score. Patience count: 1/5\u001b[0m\n",
      "\u001b[0m\u001b[37mStep 2 - Current Best Score: 0.932, Average Batch Score: 0.927 - Best Batch Score: 0.932\u001b[0m\n",
      "\u001b[0m\u001b[37mStep 3 - Current Best Score: 0.945, Average Batch Score: 0.930 - Best Batch Score: 0.945\u001b[0m\n",
      "\u001b[0m\u001b[37mStep 4 - Current Best Score: 0.955, Average Batch Score: 0.946 - Best Batch Score: 0.955\u001b[0m\n",
      "\u001b[0m\u001b[37mStep 5 - Current Best Score: 0.955, Average Batch Score: 0.933 - Best Batch Score: 0.946\u001b[0m\n",
      "\u001b[0m\u001b[37mNo improvement in best_score. Patience count: 1/5\u001b[0m\n",
      "\u001b[0m\u001b[37mStep 6 - Current Best Score: 0.955, Average Batch Score: 0.928 - Best Batch Score: 0.945\u001b[0m\n",
      "\u001b[0m\u001b[37mNo improvement in best_score. Patience count: 2/5\u001b[0m\n",
      "\u001b[0m\u001b[37mNo improvement in best_score for 2 steps. Adapted temperature to 1.10.\u001b[0m\n",
      "\u001b[0m\u001b[37mStep 7 - Current Best Score: 0.955, Average Batch Score: 0.915 - Best Batch Score: 0.929\u001b[0m\n",
      "\u001b[0m\u001b[37mNo improvement in best_score. Patience count: 3/5\u001b[0m\n",
      "\u001b[0m\u001b[31mERROR - Error occurred while evaluating solution [63, 0.24]: not enough values to unpack (expected 3, got 2)\u001b[0m\n",
      "\u001b[0m\u001b[31mERROR - Error occurred while evaluating solution [64, 0.21]: not enough values to unpack (expected 3, got 2)\u001b[0m\n",
      "\u001b[0m\u001b[37mStep 8 - Current Best Score: 0.955, Average Batch Score: -inf - Best Batch Score: 0.928\u001b[0m\n",
      "\u001b[0m\u001b[37mNo improvement in best_score. Patience count: 4/5\u001b[0m\n",
      "\u001b[0m\u001b[37mNo improvement in best_score for 2 steps. Adapted temperature to 1.21.\u001b[0m\n",
      "\u001b[0m\u001b[37mStep 9 - Current Best Score: 0.955, Average Batch Score: 0.888 - Best Batch Score: 0.916\u001b[0m\n",
      "\u001b[0m\u001b[37mNo improvement in best_score. Patience count: 5/5\u001b[0m\n",
      "\u001b[0m\u001b[33mWARNING - Early stopping triggered at step 9.\u001b[0m\n",
      "\u001b[0m\u001b[37mExecution time of maximize: 521.958 seconds\u001b[0m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "results = opro.maximize(init_samples=random_hps, init_scores=accuracies, num_steps=250, batch_size=batch_size, callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "plot_scores() got an unexpected keyword argument 'max_steps'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllmize\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplotting\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plot_scores\n\u001b[0;32m----> 3\u001b[0m \u001b[43mplot_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: plot_scores() got an unexpected keyword argument 'max_steps'"
     ]
    }
   ],
   "source": [
    "from llmize.utils.plotting import plot_scores\n",
    "\n",
    "plot_scores(results, max_steps=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
